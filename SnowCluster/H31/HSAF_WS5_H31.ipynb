{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H SAF H31 (MSG/SEVIRI) Snow Extent\n",
    "\n",
    "### Niilo Siljamo (FMI)\n",
    "\n",
    "***\n",
    "\n",
    "In this session, the basic properties and use of the H SAF H31 (MSG/SEVIRI Snow Extent) product will be presented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geostationary vs polar orbit\n",
    "\n",
    "<img src=\"img/sats.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H31 properties and development principles\n",
    "***\n",
    "The H31 snow extent product is\n",
    "1. daily (since 2008)\n",
    "2. full disk (since 2015, earlier it was produced in 4 regions (Euro, NAfr, SAfr, SAme)\n",
    "3. MSG/SEVIRI\n",
    "4. binary snow extent (snow/no snow) product\n",
    "5. based on optical remote sensing data (visible light, IR)\n",
    "\n",
    "The product is developed using so called empirical approach, which means that the rules used in the classification algorithm are based on large number (over 0.5 million) hand classified pixels which cover different land cover types, different snow cover situations and different light conditions. This important because snow cover is highly variable.\n",
    "\n",
    "Both H31 and H32 snow extent products are developed based on these principles:\n",
    "1. Accuracy over coverage (do not force classification, avoid misclassifications)\n",
    "2. Single-source data (satellite data only, do not use auxiliary snow data such as weather station observations)\n",
    "3. Directness: avoid redundant steps (such as cloud masking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow cover examples: Basics\n",
    "***\n",
    "Ideal snow cover for satellite detection would be something like this:\n",
    "<img src=\"img/p1020668.jpg\" width=\"700\">\n",
    "\n",
    "But snow cover is rarely ideal. We may have new patchy snow:\n",
    "<img src=\"img/2005-12-11++12-34-23.jpg\" width=\"700\">\n",
    "\n",
    "or patchy melting snow:\n",
    "<img src=\"img/natalie1241507401.jpg\" width=\"500\">\n",
    "<img src=\"img/p1030096.jpg\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow cover examples: Forests\n",
    "***\n",
    "\n",
    "Vegetation has also huge impact on surface properties. Long grass and shrubs can hinder snow detection, but in satellite snow detection the most relevant vegetation type are different forests. Things to consider are:\n",
    "1. Tree species (evergreen vs deciduous)\n",
    "2. Forest density\n",
    "3. Viewing angles (nadir vs edge of detection disk)\n",
    "4. Snow on trees\n",
    "5. Shadows\n",
    "\n",
    "#### Forests\n",
    "Evergreen trees can prevent surface detection partly or completely\n",
    "<img src=\"img/p1030061.jpg\" width=\"700\">\n",
    "\n",
    "Deciduous trees are partly transparent from satellites. You can see the surface, but dark tree trunks may change the view\n",
    "<img src=\"img/IMG_20191107_084547_01.jpg\" width=\"700\">\n",
    "\n",
    "unless they are snow covered\n",
    "<img src=\"img/IMG_20190206_102833.jpg\" width=\"700\">\n",
    "\n",
    "Sometimes trees can be completely snow covered\n",
    "<img src=\"img/2005-11-27++10-45-37-rot.jpg\" width=\"400\">\n",
    "\n",
    "Forests density varies quite a lot even in one satellite pixel\n",
    "<img src=\"img/natalie1268909356.jpg\" width=\"700\">\n",
    "\n",
    "#### Viewing angles\n",
    "Trees are not the same in all viewing angles. In nadir, you can see the canopy from top, but not the surface under the tree. Near the edge you see the canopy from the side, but also the area under the tree. The canopy blocks the view further away from the tree.\n",
    "<img src=\"img/natalie1236940373.jpg\" width=\"500\">\n",
    "\n",
    "#### Shadows\n",
    "Of course, you must not forget the shadows. Optical remote sensing of the surface needs cloud free daylight conditions and that means there will be shadows. Those parts of the surface which are in the shadow look different that those parts which are in direct sunlight.\n",
    "<img src=\"img/natalie1237365379.jpg\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaos\n",
    "***\n",
    "Quite often chaos is the best word when you want to describe what you see from space\n",
    "\n",
    "<img src=\"img/2006-03-07++15-46-28.jpg\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H31 algorithm\n",
    "***\n",
    "Optical snow detection is based on the varying reflective properties of different surface types (including clouds in this case). These differences can be utilized in the snow detection algorithm.\n",
    "\n",
    "<img src=\"img/oton_spektri_crop.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, what next\n",
    "***\n",
    "Now, we know that different surfaces and clouds have different reflective properties. How can we use that idea to develop something practical? \n",
    "\n",
    "<img src=\"img/england.png\" width=\"900\">\n",
    "\n",
    "We can use data from different channels to create RGB images where snow, clouds, snow free surface and seas and lakes are easy to recognize, at least by humans. The challenge is how to tell that to computers. How to tell that slightly different yellow or red shades mean different things, such as ice clouds and snow?\n",
    "\n",
    "<img src=\"img/hills.png\" width=\"900\">\n",
    "\n",
    "The old way (used during the development of the H31 algorithm) is to collect lots of example cases of different surface types and then try to find classification rules which produce correct results. More modern way is still to collect that example data set and use it as training data and develop an AI based algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-phase H31 algorithm\n",
    "\n",
    "The H31 algorithm uses radiances and brightness temperatures in 6 SEVIRI channels. The algorithm aims to detect snow covered and snow free surfaces without any preliminary steps such as cloud masking. Each pixels is either snow covered, snow free, partially snow covered (not used much), water, unclassified or unprocessed (space outside the SEVIRI detection disk). The algorithm consists of about 20 thresholding rules, which aim to detect whether the land pixels are snow covered or snow free. If this can not be decided, the pixels will be unclassified by default. These unclassified pixels include cloydy and night pixels and also those pixels which are too difficult to classify reliably.\n",
    "\n",
    "\n",
    "The H31 algorithm consists of two phases. First phase produces single image snow cover products (SC1) every 15 minutes. Then, the phase 2 merges all these single image snow products and produces the daily (SC2) H31 product.\n",
    "<img src=\"img/SnowFlow.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product validation\n",
    "***\n",
    "All satellite products should be validated before use. The best way is to compare satellite products and observations. In this case, SYNOP observations of snow depth and the state of the ground were used. More about validation e.g. in the paper mentioned above or in my thesis:\n",
    "\n",
    "Siljamo, N 2020, 'Empirical Approach to Satellite Snow Detection', Helsingin yliopisto, Helsinki. <http://hdl.handle.net/10138/317970>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the data?\n",
    "-----------------\n",
    "The H31 product can be retrieved in NRT or from web archives.\n",
    "\n",
    "Near real time data is available via:\n",
    "- EUMETCast\n",
    "- Automatic FTP Dissemination (LSA SAF by request)\n",
    "\n",
    "Archived older product files are available either from H SAF website (https://hsaf.meteoam.it/) or from the LSA SAF website (https://landsaf.ipma.pt/). Data download requires registration in both systems.\n",
    "\n",
    "You can get the data from H SAF website:\n",
    "<img src=\"img/hsaf1.png\" width=\"800\">\n",
    "<img src=\"img/hsaf2.png\" width=\"800\">\n",
    "<img src=\"img/hsaf3.png\" width=\"800\">\n",
    "\n",
    "or from LSA SAF website:\n",
    "<img src=\"img/landsaf1.png\" width=\"800\">\n",
    "<img src=\"img/landsaf2.png\" width=\"800\">\n",
    "<img src=\"img/landsaf3.png\" width=\"800\">\n",
    "\n",
    "The file format used is HDF5 and the contents of the files are described in the product documentation (also available from both web sites. In each file, daily snow extent product is presented for full MSG/SEVIRI disk.\n",
    "\n",
    "In this demo, one example product file (HDF5_LSASAF_MSG_SC2_MSG-Disk_202002080000) will be used. The data is not included in this jupyter notebook package, but the code will download the data package from the net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python: Loading and plotting the data\n",
    "-----------------\n",
    "\n",
    "There are many ways to read the files and use the data. For example, we can use h5py package.\n",
    "\n",
    "First, import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we must download the test data set. If the data has been downloaded earlier, this step can be skipped. Or you can retrieve similar files from product data archives (HSAF or LSA SAF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "\n",
    "urllib.request.urlretrieve(\"https://edrop.zamg.ac.at/owncloud/index.php/s/qyTy8EjEadRPyng/download?path=%2FData%2FH%20SAF%20Snow%20products&files=H31.zip\",\"H31.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the download finishes.\n",
    "\n",
    "Downloaded data package H31.zip must be uncompressed before it can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('H31.zip', 'r') as f:\n",
    "    #extract in current directory\n",
    "    f.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read the data. For snow extent, you do not need scale and offset values, but other attributes can be read in the same way. The attributes are described in the product documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_fn = 'data/HDF5_LSASAF_MSG_SC2_MSG-Disk_202002080000'\n",
    "with h5py.File(snow_fn, 'r') as fid:\n",
    "        dataset = fid['SC']\n",
    "        sc_data = np.array(dataset)\n",
    "        #scale = dataset.attrs['SCALING_FACTOR']\n",
    "        #offset = dataset.attrs['OFFSET']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see that the snow extent data has been read into the variable sc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data[2380:2390, 1200:1210]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array contains integers as expected.\n",
    "\n",
    "Every pixel in the product describes the snow extent using the classifications:<br>\n",
    "0 Pixel is not processed<br>\n",
    "1 Full snow cover<br>\n",
    "2 Partial snow cover<br>\n",
    "3 No snow<br>\n",
    "4 Pixel could not be classified (night, clouds, classification uncertain<br>\n",
    "5 Water\n",
    "\n",
    "Now the data can then be used in applications. \n",
    "\n",
    "Next step can be e.g. plotting the data to see what kind of data we have. First, we create a figure and define a colormap, which helps to understand the image. Then we plot the image. We must define the minimum and maximum values in the array for that to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,20))\n",
    "sc_colormap = colors.ListedColormap(['gray','white','lightgrey',\n",
    "                                  'forestgreen','black','deepskyblue'])\n",
    "plt.imshow(sc_data, vmin=0, vmax=6, cmap=sc_colormap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python: Reprojecting \n",
    "-----------------\n",
    "\n",
    "\n",
    "### Pytroll reprojection and plotting example\n",
    "-----------------\n",
    "\n",
    "\n",
    "\n",
    "Pytroll can be used to analyse and process the data. We have used NASA Worldview and retrieved a snapshot image (MODIS and/or VIIRS) in geoTIFF format (saved as Europe_5km.tiff). We can then use Pytroll functions to reproject H31 Snow Extent to the same projection used in the geotiff.\n",
    "\n",
    "First we must import more packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from satpy import Scene\n",
    "from pyresample import kd_tree, geometry\n",
    "import h5py\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from pyproj import CRS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='pyproj')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define some functions. The reprojected_to_tiff reads the geotiff and reprojects the snow extent to the same projection and cuts the same area from the data. We must also read the pixel coordinates of the H31 product from coordinate files. See the pytroll documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprojected_to_tiff(ref_fname, snow_fname, resolution=0.10, src='H31'):\n",
    "    \"\"\"\n",
    "    Reproject snow product to geotiff area\n",
    "    \"\"\"\n",
    "\n",
    "    # Reference image filename\n",
    "    # ref_fname = sys.argv[0]\n",
    "\n",
    "    # Input data filename\n",
    "    # snow_fname = sys.argv[1]\n",
    "\n",
    "    # Fixed LAT and LON files\n",
    "    lat_fn = 'data/HDF5_LSASAF_MSG_LAT_MSG-Disk_201807110815'\n",
    "    lon_fn = 'data/HDF5_LSASAF_MSG_LON_MSG-Disk_201807110815'\n",
    "\n",
    "    # Read area of the reference image\n",
    "    scn = Scene(reader='generic_image', filenames=[ref_fname])\n",
    "    scn.load(['image'])\n",
    "    target_area = scn['image'].area\n",
    "\n",
    "    # Read data and coordinates\n",
    "    # Read snow data and coordinates\n",
    "    if src == 'H31':\n",
    "        with h5py.File(snow_fname, 'r') as fid:\n",
    "            data = fid['SC'][()]\n",
    "        with h5py.File(lat_fn, 'r') as fid:\n",
    "            lats = fid['LAT'][()]/100\n",
    "        with h5py.File(lon_fn, 'r') as fid:\n",
    "            lons = fid['LON'][()]/100\n",
    "\n",
    "    # Create swath definition for the input data\n",
    "    swath_def = geometry.SwathDefinition(lons=lons, lats=lats)\n",
    "\n",
    "    # Resample using nearest-neighbour interpolation\n",
    "    result = kd_tree.resample_nearest(swath_def, data, target_area,\n",
    "                                      radius_of_influence=100000)\n",
    "\n",
    "    return scn['image'], result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define plot_2, which contains the actual code for drawing the MODIS/VIIRS image and reprojected snow product. The code <br>\n",
    "1. creates a colormap<br>\n",
    "2. transposes and scales the tiff image<br>\n",
    "3. plots the MODIS/VIIRS image<br>\n",
    "4. plots the snow map with legend\n",
    "\n",
    "If you want to save the image you can use one of the commented (marked by #) plt.savefig lines at the end. If this code is used in python shell or in a package, the line plt.ion() turns on the interactive mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2(tiff_image, snow1, title0='', title1='', figname='tmp', single='no'):\n",
    "    \"\"\"\n",
    "    Plot NASA Worldview vs H31/H32.\n",
    "    \"\"\"\n",
    "    sc_colormap = colors.ListedColormap(['gray','white','lightgrey',\n",
    "                                  'forestgreen','black','deepskyblue'])\n",
    "    # Transpose and scale tiff\n",
    "    modis = np.zeros((snow1.shape[0], snow1.shape[1], 3), dtype=float)\n",
    "    modis[:,:,0] = tiff_image[0]/255\n",
    "    modis[:,:,1] = tiff_image[1]/255\n",
    "    modis[:,:,2] = tiff_image[2]/255\n",
    "\n",
    "    plt.figure(1,figsize=(8,10))\n",
    "    plt.clf()\n",
    "    #plt.ion()\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(title0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(modis)#\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.title(title1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(snow1, vmin=0, vmax=6, cmap=sc_colormap)\n",
    "    plt.legend([mpatches.Patch(facecolor='white',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='lightgrey',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='forestgreen',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='deepskyblue',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='black',edgecolor='black')], \n",
    "               ['snow', 'partial', 'no snow', 'water','not classified'], loc=3)#\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig(figname+\".pdf\", papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "    #plt.savefig(figname+\".png\", papertype = 'a4', orientation = 'portrait', format = 'png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this is used in plot_areaH31 which calls reprojected_to_tiff with suitable parameters and then the plotting function with the data returned from the reprojection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_areaH31(tiff_name='data/Europe_5km.tiff', snow_name='data/HDF5_LSASAF_MSG_SC2_MSG-Disk_202002080000', day='20200208', figname='', single='no'):\n",
    "    \"\"\"\n",
    "    Plot the area in the geotiff, 1x2 (MODIS/VIIRS, H31).\n",
    "    \"\"\"\n",
    "    tkuva, snow1 = reprojected_to_tiff(\n",
    "        tiff_name, snow_name, resolution=0.01, src='H31')\n",
    "    plot_2(tkuva, snow1,\n",
    "           title0='MODIS '+day,\n",
    "           title1='H31 '+day,\n",
    "           figname=figname+'H31',\n",
    "           single=single)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the code which needs a little bit of time to draw the image you can use to compare MODIS/VIIRS RGB image and H31 Snow Extent product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areaH31(tiff_name='data/Europe_5km.tiff', snow_name='data/HDF5_LSASAF_MSG_SC2_MSG-Disk_202002080000',\n",
    "             day='20200208', figname='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## How to use satellite snow product in NWP data assimilation \n",
    "***\n",
    "\n",
    "Snow extent products can be used in weather model data assimilation. It will not be the only or even primary data source for snow cover, but satellite snow extent product can improve snow analysis especially in areas where weather stations do not measure snow cover.\n",
    "\n",
    "The picture below presents one way to use satellite snow extent data in weather model data assimilation in three step. In step 1, high resolution satellite data is converted to suitable resolution for the weather model. In step 2 these observations are converted to pseudo-observations which can be assimilated in the normal data assimilation process in step 3.\n",
    "\n",
    "<img src=\"img/NWP_example.png\" >\n",
    "\n",
    "### Current users\n",
    "\n",
    "At the moment, the H31 snow extent product is used in the Met Office local area model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
