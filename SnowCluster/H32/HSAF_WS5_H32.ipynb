{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H SAF H32 Snow Extent\n",
    "\n",
    "### Niilo Siljamo (FMI)\n",
    "\n",
    "***\n",
    "In this session, H SAF H32 (Metop/AVHRR Snow Extent) product will be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polar orbit vs Geostationary orbit\n",
    "\n",
    "<img src=\"img/sats.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H32 properties and development principles\n",
    "***\n",
    "The H32 snow extent product is\n",
    "1. Daily (since 2015)\n",
    "2. Global (0.01 x 0.01 degrees lat-lon grid)\n",
    "3. Metop/AVHRR \n",
    "4. binary snow extent (snow/no snow) product\n",
    "5. based on optical remote sensing data (visible light, IR)\n",
    "\n",
    "Because snow cover is highly variable, the product is developed using so called empirical approach, which means that the rules used in the classification algorithm are based on large number (over 0.5 million) hand classified pixels which cover different land cover types, different snow cover situations and different light conditions. In the future, similar hand classified data could be used as training data for machine learning.\n",
    "\n",
    "During the development of the H31 and H32 snow extent products, the work was based on these principles:\n",
    "1. Accuracy over coverage (do not force classification, avoid misclassifications)\n",
    "2. Single-source data (satellite data only, do not use auxiliary snow data such as weather station observations)\n",
    "3. Directness (avoid redundant steps, such as cloud masking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow cover examples: Basics\n",
    "***\n",
    "Ideal snow cover for satellite detection would be something like this:\n",
    "\n",
    "<img src=\"img/p1020668.jpg\" width=\"700\">\n",
    "\n",
    "But snow cover is rarely ideal. We may have new patchy snow:\n",
    "\n",
    "<img src=\"img/2005-12-11++12-34-23.jpg\" width=\"700\">\n",
    "\n",
    "or patchy melting snow:\n",
    "\n",
    "<img src=\"img/natalie1241507401.jpg\" width=\"500\">\n",
    "<img src=\"img/p1030096.jpg\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow cover examples: Forests\n",
    "***\n",
    "\n",
    "Vegetation has also huge impact on surface properties. Long grass and shrubs can hinder snow detection, but in satellite snow detection the most relevant vegetation type are different forests. Things to consider are:\n",
    "1. Tree species (evergreen vs others)\n",
    "2. Forest density (e.g. dense evergreen forest vs sparse deciduous forests)\n",
    "3. Viewing angles (nadir vs edge of detection disk)\n",
    "4. Snow on trees\n",
    "5. Shadows\n",
    "\n",
    "#### Forests\n",
    "Evergreen trees can prevent surface detection partly or completely\n",
    "<img src=\"img/p1030061.jpg\" width=\"700\">\n",
    "\n",
    "Deciduous trees are partly transparent from satellites. You can see the surface, but sometimes dark tree trunks may have impact\n",
    "<img src=\"img/IMG_20191107_084547_01.jpg\" width=\"700\">\n",
    "\n",
    "unless they are snow covered\n",
    "<img src=\"img/IMG_20190206_102833.jpg\" width=\"700\">\n",
    "\n",
    "Sometimes trees can be completely snow covered\n",
    "<img src=\"img/2005-11-27++10-45-37-rot.jpg\" width=\"400\">\n",
    "\n",
    "Forests density varies quite a lot even in one satellite pixel\n",
    "<img src=\"img/natalie1268909356.jpg\" width=\"700\">\n",
    "\n",
    "#### Viewing angles\n",
    "Trees are not the same in all viewing angles. In nadir, you can see the canopy, but not the surface under the tree. Near the edge you see the canopy from the side, and also the area under the tree. The canopy covers the surface further away from the tree.\n",
    "<img src=\"img/natalie1236940373.jpg\" width=\"500\">\n",
    "\n",
    "#### Shadows\n",
    "Of course, you must not forget the shadows. Optical remote sensing of the surface needs cloud free daylight conditions and that means there will be shadows. Those parts of the surface which are in the shadow look different that those parts which are in direct sunlight.\n",
    "<img src=\"img/natalie1237365379.jpg\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaos\n",
    "***\n",
    "Quite often chaos is the best word when you want to describe what you see from space\n",
    "\n",
    "<img src=\"img/2006-03-07++15-46-28.jpg\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H32 algorithm\n",
    "***\n",
    "Optical snow detection is based on the varying reflective properties of different surface types (including clouds in this case). These differences can be utilized in the snow detection algorithm.\n",
    "\n",
    "<img src=\"img/oton_spektri_crop.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, what next\n",
    "***\n",
    "Now, we know that different surfaces and clouds have different reflective properties. How can we use that idea to develop something practical? \n",
    "\n",
    "<img src=\"img/idea.png\" width=\"800\">\n",
    "\n",
    "We can use data from different channels to create RGB images where snow, clouds, snow free surface and seas and lakes are easy to recognize, at least by humans. The challenge is how to tell that to computers. How to tell that slightly different yellow or red shades mean different things, such as ice clouds and snow?\n",
    "\n",
    "The old way (used during the development of the H32 algorithm) is to collect lots of example cases of different surface types and then try to find classification rules which produce correct results. More modern way is still to collect that example data set and use it as training data and develop an AI based algorithm.\n",
    "\n",
    "Image from: Siljamo, N., Hyv채rinen, O., Riihel채, A., & Suomalainen, M. (2020). MetOp/AVHRR Snow Detection Method for Meteorological Applications, Journal of Applied Meteorology and Climatology, 59(12), 2001-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-phase H32 algorithm\n",
    "\n",
    "The H32 algorithm uses radiances and brightness temperatures in 5 AVHRR channels. The algorithm aims to detect snow covered and snow free surfaces without any preliminary steps such as cloud masking. Each pixels is either snow covered, snow free, partially snow covered (not used much), water or unclassified. The algorithm consists of about 20 thresholding rules, which aim to detect whether the land pixels are snow covered or snow free. If this can not be decided, the pixels will be unclassified by default. These unclassified pixels include cloydy and night pixels and also those pixels which are too difficult to classify reliably.\n",
    "\n",
    "The H32 algorithm consists of two phases. First phase produces single image snow cover products (SC1) in so called PDU units (3 minutes of data). Then, the phase 2 merges all these single image snow products and produces the daily global (SC2) H32 product.\n",
    "<img src=\"img/SnowFlow.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product validation\n",
    "***\n",
    "All satellite products should be validated before use. The best way is to compare satellite products and observations. In this case, SYNOP observations of snow depth and the state of the ground were used. More about validation e.g. in the paper mentioned above or in my thesis:\n",
    "\n",
    "Siljamo, N 2020, 'Empirical Approach to Satellite Snow Detection', Helsingin yliopisto, Helsinki. <http://hdl.handle.net/10138/317970>\n",
    "\n",
    "Let's see an example of validation results based on surface observations. This image is from: Siljamo, N., Hyv채rinen, O., Riihel채, A., & Suomalainen, M. (2020). MetOp/AVHRR Snow Detection Method for Meteorological Applications, Journal of Applied Meteorology and Climatology, 59(12), 2001-2019\n",
    "\n",
    "Validation measures acronyms used:\n",
    "1. H = Hit Rate\n",
    "2. F = False Alarm Rate\n",
    "3. PC = Proportion Correct\n",
    "4. FAR = False Alarm Ratio\n",
    "5. HSS = Heidke Skill Score\n",
    "6. SEDI = Symmetric Extremal Dependence Index\n",
    "\n",
    "\n",
    "<img src=\"img/global_metop_ok_pns_series.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the data?\n",
    "-----------------\n",
    "The H32 product can be retrieved in NRT or from web archives. \n",
    "\n",
    "Near real time data is available via:\n",
    "- EUMETCast\n",
    "- Automatic FTP Dissemination (LSA SAF by request)\n",
    "\n",
    "Archived older product files are available either from H SAF website (https://hsaf.meteoam.it/) or from the LSA SAF website (https://landsaf.ipma.pt/). Data download requires registration in both systems.\n",
    "\n",
    "You can get the data from H SAF website:\n",
    "<img src=\"img/hsaf1.png\" width=\"800\">\n",
    "<img src=\"img/hsaf2.png\" width=\"800\">\n",
    "<img src=\"img/hsaf4.png\" width=\"800\">\n",
    "\n",
    "or from LSA SAF website:\n",
    "<img src=\"img/landsaf1.png\" width=\"800\">\n",
    "<img src=\"img/landsaf2.png\" width=\"800\">\n",
    "<img src=\"img/landsaf3.png\" width=\"800\">\n",
    "\n",
    "The file format used is HDF5 and the contents of the files are described in the product documentation (also available from both web sites. In each file, daily snow extent product is presented for full MSG/SEVIRI disk.\n",
    "\n",
    "In this demo, one example product file (HDF5_LSASAF_M01-AVHR_EDSC_GLOBE_202002080000) will be used. The data is not included in this jupyter notebook package, but the code will download the data package from the net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the data in Python?\n",
    "***\n",
    "\n",
    "There are many ways to read the files and plot the data. For example, we can use h5py package for file i/o and matplotlib for graphics.\n",
    "\n",
    "First, import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we must download the test data set. If the data package has been downloaded earlier, this step can be skipped. Or you can retrieve similar files from product data archives (HSAF or LSA SAF).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "\n",
    "urllib.request.urlretrieve(\"https://edrop.zamg.ac.at/owncloud/index.php/s/qyTy8EjEadRPyng/download?path=%2FData%2FH%20SAF%20Snow%20products&files=H32.zip\",\"H32.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the download finishes.\n",
    "\n",
    "Download H32.zip must be uncompressed before it can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('H32.zip', 'r') as f:\n",
    "    #extract in current directory\n",
    "    f.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can read the data. For snow extent, you do not need scale and offset values, but other attributes can be read in the same way. The attributes are described in the product documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_fn = 'data/HDF5_LSASAF_M01-AVHR_EDSC_GLOBE_202002080000'\n",
    "with h5py.File(snow_fn, 'r') as fid:\n",
    "       \n",
    "        dataset = fid['SC']\n",
    "        sc_data = np.array(dataset)\n",
    "        #scale = dataset.attrs['SCALING_FACTOR']\n",
    "        #offset = dataset.attrs['OFFSET']\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see that the snow extent data has been read into the variable sc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data[4580:4590, 18700:18710]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array contains integers as expected.\n",
    "\n",
    "Every pixel in the product describes the snow extent using the classifications:<br>\n",
    "0 Pixel is not processed<br>\n",
    "1 Full snow cover<br>\n",
    "2 Partial snow cover<br>\n",
    "3 No snow<br>\n",
    "4 Pixel could not be classified (night, clouds, classification uncertain<br>\n",
    "5 Water\n",
    "\n",
    "Now the data can then be used in applications. \n",
    "\n",
    "Next step can be e.g. plotting the data to see what kind of data we have. First, we create a figure and define a colormap, which helps to understand the image. Then we plot the image. We must define the minimum and maximum values in the array for that to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,20))\n",
    "sc_colormap = colors.ListedColormap(['gray','white','lightgrey',\n",
    "                                  'forestgreen','black','deepskyblue'])\n",
    "plt.imshow(sc_data, vmin=0, vmax=6, cmap=sc_colormap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pytroll reprojection and plotting example\n",
    "***\n",
    "\n",
    "Pytroll can be used to analyse and process the data. We have used NASA Worldview and retrieved a snapshot image (MODIS and/or VIIRS) in geoTIFF format (saved as Europe_5km.tiff). We can then use Pytroll functions to reproject H32 Snow Extent to the same projection used in the geotiff.\n",
    "\n",
    "First we must import more packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from satpy import Scene\n",
    "from pyresample import kd_tree, geometry\n",
    "import h5py\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from pyproj import CRS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='pyproj')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define some functions. The reprojected_to_tiff reads the geotiff and reprojects the snow extent to the same projection and cuts the same area from the data. We must also create arrays (lats and lons) which contain the pixels coordinates of the H32 product. See the pytroll documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprojected_to_tiff(ref_fname, snow_fname, resolution=0.10):\n",
    "    \"\"\"\n",
    "    Reproject snow product to geotiff area\n",
    "    \"\"\"\n",
    "\n",
    "    # Read area of the reference image\n",
    "    scn = Scene(reader='generic_image', filenames=[ref_fname])\n",
    "    scn.load(['image'])\n",
    "    target_area = scn['image'].area\n",
    "    \n",
    "    # Read data and coordinates\n",
    "    # Read snow data and coordinates\n",
    "    with h5py.File(snow_fname,'r') as fid:\n",
    "        data = fid['SC'][()]\n",
    "        lon_vect = np.arange(-180.00, 179.99, resolution)\n",
    "        lat_vect = np.arange(89.99, -89.99, -resolution)\n",
    "        lons,lats = np.meshgrid(lon_vect, lat_vect)\n",
    "\n",
    "    # Create swath definition for the input data\n",
    "    swath_def = geometry.SwathDefinition(lons=lons, lats=lats)\n",
    "    \n",
    "    # Resample using nearest-neighbour interpolation\n",
    "    result = kd_tree.resample_nearest(swath_def, data, target_area, \n",
    "                                      radius_of_influence=1000)\n",
    "\n",
    "    return scn['image'], result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define plot_2, which contains the actual code for drawing the MODIS/VIIRS image and reprojected snow product in the same figure. The code <br>\n",
    "1. creates a colormap<br>\n",
    "2. transposes and scales the tiff image<br>\n",
    "3. plots the MODIS/VIIRS image<br>\n",
    "4. plots the snow map with legend\n",
    "\n",
    "If you want to save the image you can use one of the commented (marked by #) plt.savefig lines at the end. If this code is used in python shell or in a package, the line plt.ion() turns on the interactive mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2(tiff_image, snow1, title0='', title1='', figname='tmp', single='no'):\n",
    "    \"\"\"\n",
    "    Plot NASA Worldview vs H31/H32.\n",
    "    \"\"\"\n",
    "    sc_colormap = colors.ListedColormap(['gray','white','lightgrey',\n",
    "                                  'forestgreen','black','deepskyblue'])\n",
    "    # Transpose and scale tiff\n",
    "    modis = np.zeros((snow1.shape[0], snow1.shape[1], 3), dtype=float)\n",
    "    modis[:,:,0] = tiff_image[0]/255\n",
    "    modis[:,:,1] = tiff_image[1]/255\n",
    "    modis[:,:,2] = tiff_image[2]/255\n",
    "\n",
    "    plt.figure(1,figsize=(8,10))\n",
    "    plt.clf()\n",
    "    #plt.ion()\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(title0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(modis)#\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.title(title1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(snow1, vmin=0, vmax=6, cmap=sc_colormap)\n",
    "    plt.legend([mpatches.Patch(facecolor='white',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='lightgrey',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='forestgreen',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='deepskyblue',edgecolor='black'), \n",
    "                mpatches.Patch(facecolor='black',edgecolor='black')], \n",
    "               ['snow', 'partial', 'no snow', 'water','not classified'], loc=3)#\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig(figname+\".pdf\", papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "    #plt.savefig(figname+\".png\", papertype = 'a4', orientation = 'portrait', format = 'png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this is used in plot_areaH32 which calls reprojected_to_tiff with suitable parameters and then the plotting function with the data returned from the reprojection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_areaH32(tiff_name='some.tiff', snow_name='H32_filename', day='', figname='', single='no'):\n",
    "    \"\"\"\n",
    "    Plot the area in the geotiff, 1x2 (MODIS, H32).\n",
    "    \"\"\"\n",
    "    t_image, snow1 = reprojected_to_tiff(tiff_name,snow_name,resolution=0.01)\n",
    "    plot_2(t_image, snow1,\n",
    "           title0='MODIS '+day,\n",
    "           title1='H32 '+day,\n",
    "           figname=figname+'H32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the code which needs a little bit of time to draw the image you can use to compare MODIS/VIIRS RGB image and H32 Snow Extent product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areaH32(tiff_name='data/Europe_5km.tiff', snow_name='data/HDF5_LSASAF_M01-AVHR_EDSC_GLOBE_202002080000', \n",
    "             day='20200208', figname='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### NWP data assimilation example\n",
    "-----------------\n",
    "\n",
    "Snow extent products can be used in weather model data assimilation. It will not be the only or even primary data source for snow cover, but satellite snow extent product can improve snow analysis especially in areas where weather stations are sparse.\n",
    "\n",
    "The picture below presents one way to convert satellite snow extent data in weather model data assimilation in three step. In step 1, high resolution satellite data is converted to suitable resolution for the weather model. In step 2 these observations are converted to pseudo-observations which can be assimilated in the normal data assimilation process in step 3.\n",
    "<img src=\"img/NWP_example.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/barrels.png\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Barrel_production.png\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
